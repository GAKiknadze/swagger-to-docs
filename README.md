# üìö OpenAPI to Markdown Documentation Generator

–ú–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è OpenAPI/Swagger —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –≤ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ Markdown —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LangChain –∏ LLM.

## ‚ú® –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- ü§ñ **LangChain Integration**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LangChain Expression Language (LCEL) –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
- üåç **–ú–Ω–æ–∂–µ—Å—Ç–≤–æ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤**: –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Ollama, OpenAI, Anthropic, HuggingFace
- üìÑ **–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è**: –û—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–≥–∞ –∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞
- üè∑Ô∏è **–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ç–µ–≥–∞–º**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
- üõ°Ô∏è **–ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏**: –î–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
- üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞**: –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ OpenAPI
- üåê **–ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: –†—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫–∏
- üìù **–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**: –ì–æ—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã curl –∑–∞–ø—Ä–æ—Å–æ–≤

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install -e ".[ollama]"
# –∏–ª–∏ –¥–ª—è OpenAI:
pip install -e ".[openai]"
# –∏–ª–∏ –¥–ª—è Claude:
pip install -e ".[anthropic]"
```

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

#### –° Ollama (–ª–æ–∫–∞–ª—å–Ω–æ)

```bash
# 1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞
ollama serve

# 2. –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ —Å–∫–∞—á–∞–π—Ç–µ –º–æ–¥–µ–ª—å
ollama pull mistral

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
python main.py
```

#### –° OpenAI API

```bash
export OPENAI_API_KEY="sk-..."
python examples.py 2
```

#### –° Claude (Anthropic)

```bash
export ANTHROPIC_API_KEY="sk-ant-..."
python examples.py 3
```

## üìñ –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å OpenAPI —Ñ–∞–π–ª–∞–º–∏

```python
from config import LLMConfig, get_llm_from_config
from advanced_generator import AdvancedOpenAPIDocGenerator

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
llm_config = LLMConfig(provider="ollama", model="mistral")
llm = get_llm_from_config(llm_config)

# –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
generator = AdvancedOpenAPIDocGenerator(llm, output_dir="docs", language="ru")

# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
generator.process_directory("examples")
```

### –ü—Ä–∏–º–µ—Ä 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

```python
generator.process_openapi_file("examples/petstore.json")
```

### –ü—Ä–∏–º–µ—Ä 3: –ê–Ω–∞–ª–∏–∑ OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏

```python
from utils import load_openapi, OpenAPIAnalyzer

spec = load_openapi("examples/petstore.json")
analyzer = OpenAPIAnalyzer(spec)

# –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
stats = analyzer.get_statistics()
print(f"–í—Å–µ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤: {stats['total_endpoints']}")

# –ù–∞–π—Ç–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –ø–æ —Ç–µ–≥—É
pets_endpoints = analyzer.find_endpoints_by_tag("pets")

# –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ —Å—Ö–µ–º—ã
schemas = analyzer.get_all_schemas()
```

### –ü—Ä–∏–º–µ—Ä 4: –≠–∫—Å–ø–æ—Ä—Ç –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã

```python
from utils import load_openapi, OpenAPIExporter

spec = load_openapi("examples/petstore.json")
exporter = OpenAPIExporter(spec)

# –≠–∫—Å–ø–æ—Ä—Ç –≤ CSV
exporter.export_endpoints_csv("endpoints.csv")

# –≠–∫—Å–ø–æ—Ä—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ JSON
exporter.export_statistics_json("stats.json")

# –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ Postman –∫–æ–ª–ª–µ–∫—Ü–∏–∏
exporter.generate_postman_collection("postman.json")
```

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
swagger-to-docs/
‚îú‚îÄ‚îÄ main.py                    # –ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
‚îú‚îÄ‚îÄ advanced_generator.py       # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å LCEL
‚îú‚îÄ‚îÄ config.py                  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
‚îú‚îÄ‚îÄ utils.py                   # –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAPI
‚îú‚îÄ‚îÄ examples.py                # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
‚îú‚îÄ‚îÄ examples/                  # –ü—Ä–∏–º–µ—Ä—ã OpenAPI —Ñ–∞–π–ª–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ petstore.json
‚îÇ   ‚îú‚îÄ‚îÄ petstore-expanded.json
‚îÇ   ‚îú‚îÄ‚îÄ api.github.com.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ docs/                      # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
    ‚îú‚îÄ‚îÄ swagger_petstore/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md          # –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ
    ‚îÇ   ‚îú‚îÄ‚îÄ tags/              # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ç–µ–≥–∞–º
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pets.md
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ endpoints/         # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º
    ‚îÇ       ‚îú‚îÄ‚îÄ get_pets.md
    ‚îÇ       ‚îú‚îÄ‚îÄ post_pets.md
    ‚îÇ       ‚îî‚îÄ‚îÄ ...
```

## üõ†Ô∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (config.py)

```python
@dataclass
class LLMConfig:
    provider: Literal["ollama", "openai", "anthropic", "huggingface"] = "ollama"
    model: str = "mistral"
    api_key: str = ""
    base_url: str = "http://localhost:11434"  # –î–ª—è Ollama
    temperature: float = 0.7
    max_tokens: int = 2000
```

### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
@dataclass
class DocumentationConfig:
    output_dir: str = "docs"
    input_dir: str = "examples"
    include_examples: bool = True
    include_schemas: bool = True
    include_security: bool = True
    language: Literal["ru", "en"] = "ru"
    generate_toc: bool = True
    generate_diagrams: bool = False
```

## üìù API –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### OpenAPIDocumentationGenerator

–ë–∞–∑–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LangChain Chains.

**–ú–µ—Ç–æ–¥—ã:**
- `process_openapi_file(file_path)` - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω OpenAPI —Ñ–∞–π–ª
- `process_directory(directory)` - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
- `extract_endpoints(spec)` - –ò–∑–≤–ª–µ—á—å —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã
- `generate_endpoint_doc(key, endpoint, spec)` - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞

### AdvancedOpenAPIDocGenerator

–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LCEL.

**–ú–µ—Ç–æ–¥—ã:**
- `process_openapi_file(file_path)` - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å OpenAPI —Ñ–∞–π–ª
- `process_directory(directory)` - –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
- `load_spec(file_path)` - –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é

### OpenAPIAnalyzer

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç OpenAPI —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏.

**–ú–µ—Ç–æ–¥—ã:**
- `get_statistics()` - –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
- `find_endpoints_by_tag(tag)` - –ù–∞–π—Ç–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –ø–æ —Ç–µ–≥—É
- `find_endpoints_by_method(method)` - –ù–∞–π—Ç–∏ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –ø–æ HTTP –º–µ—Ç–æ–¥—É
- `get_request_body_schema(path, method)` - –ü–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—É –∑–∞–ø—Ä–æ—Å–∞
- `get_response_schemas(path, method)` - –ü–æ–ª—É—á–∏—Ç—å —Å—Ö–µ–º—ã –æ—Ç–≤–µ—Ç–æ–≤
- `list_all_endpoints()` - –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤

### OpenAPIExporter

–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã.

**–ú–µ—Ç–æ–¥—ã:**
- `export_endpoints_csv(output_path)` - CSV —Å —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞–º–∏
- `export_statistics_json(output_path)` - JSON —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
- `generate_postman_collection(output_path)` - Postman –∫–æ–ª–ª–µ–∫—Ü–∏—è

## üîß –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

### Ollama (–õ–æ–∫–∞–ª—å–Ω–æ)

–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π –∏ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç.

```python
LLMConfig(
    provider="ollama",
    model="mistral",  # –∏–ª–∏ "llama2", "neural-chat", etc.
    base_url="http://localhost:11434"
)
```

### OpenAI

–¢—Ä–µ–±—É–µ—Ç API –∫–ª—é—á.

```python
LLMConfig(
    provider="openai",
    model="gpt-3.5-turbo",  # –∏–ª–∏ "gpt-4"
    api_key="sk-..."
)
```

### Anthropic (Claude)

–¢—Ä–µ–±—É–µ—Ç API –∫–ª—é—á.

```python
LLMConfig(
    provider="anthropic",
    model="claude-3-sonnet-20240229",
    api_key="sk-ant-..."
)
```

### HuggingFace

–¢—Ä–µ–±—É–µ—Ç API –∫–ª—é—á.

```python
LLMConfig(
    provider="huggingface",
    model="meta-llama/Llama-2-7b-chat-hf",
    api_key="hf_..."
)
```

## üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

- Python >= 3.10
- langchain >= 0.1.0
- langchain-core >= 0.1.0
- langchain-community >= 0.0.1
- pyyaml >= 6.0

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### Ollama –Ω–µ –ø–æ–¥–∫–ª—é—á–∞–µ—Ç—Å—è

```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞
ollama serve

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –¥–æ—Å—Ç—É–ø–Ω–∞ –ª–∏ –º–æ–¥–µ–ª—å
ollama list

# –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞
ollama pull mistral
```

### OpenAI API –æ—à–∏–±–∫–∞

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á
export OPENAI_API_KEY="sk-..."

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
python -c "from langchain_openai import ChatOpenAI; print('OK')"
```

### –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ OpenAPI

–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–Ω—ã–π JSON/YAML:

```python
from utils import load_openapi, OpenAPIValidator

spec = load_openapi("file.json")
is_valid, errors = OpenAPIValidator.is_valid_openapi(spec)

if not is_valid:
    print("–û—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
    for error in errors:
        print(f"  - {error}")
```

## ü§ù –ö–æ–Ω—Ç—Ä–∏–±—å—é—Ç–∏–Ω–≥

–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é—Ç—Å—è pull requests –∏ issues!

## üìÑ –õ–∏—Ü–µ–Ω–∑–∏—è

MIT License

## üîó –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [OpenAPI Specification](https://spec.openapis.org/)
- [LangChain Documentation](https://python.langchain.com/)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [OpenAI API](https://platform.openai.com/docs/api-reference)

---

**–°–æ–∑–¥–∞–Ω–æ —Å ‚ù§Ô∏è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π**