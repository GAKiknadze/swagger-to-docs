"""–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OpenAPI Documentation Generator."""

from pathlib import Path
from config import LLMConfig, DocumentationConfig, get_llm_from_config
from advanced_generator import AdvancedOpenAPIDocGenerator


def example_with_ollama():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å Ollama (–ª–æ–∫–∞–ª—å–Ω–æ)."""
    print("=" * 60)
    print("Example 1: Using Ollama (Local)")
    print("=" * 60)
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º Ollama
    llm_config = LLMConfig(
        provider="ollama",
        model="mistral",  # –∏–ª–∏ "llama2", "neural-chat"
        base_url="http://localhost:11434"
    )
    
    doc_config = DocumentationConfig(
        output_dir="docs",
        input_dir="examples",
        language="ru"
    )
    
    try:
        llm = get_llm_from_config(llm_config)
        generator = AdvancedOpenAPIDocGenerator(llm, output_dir=doc_config.output_dir)
        generator.process_directory(doc_config.input_dir)
    except Exception as e:
        print(f"Error: {e}")
        print("\nüí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω–∞:")
        print("   1. ollama serve")
        print("   2. ollama pull mistral")


def example_with_openai():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å OpenAI API."""
    print("=" * 60)
    print("Example 2: Using OpenAI GPT")
    print("=" * 60)
    
    import os
    
    # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("‚ùå OPENAI_API_KEY not set")
        return
    
    llm_config = LLMConfig(
        provider="openai",
        model="gpt-3.5-turbo",  # –∏–ª–∏ "gpt-4"
        api_key=api_key,
        temperature=0.7
    )
    
    doc_config = DocumentationConfig(
        output_dir="docs",
        input_dir="examples",
        language="ru"
    )
    
    try:
        llm = get_llm_from_config(llm_config)
        generator = AdvancedOpenAPIDocGenerator(llm, output_dir=doc_config.output_dir)
        generator.process_directory(doc_config.input_dir)
    except Exception as e:
        print(f"Error: {e}")


def example_with_anthropic():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å Claude (Anthropic)."""
    print("=" * 60)
    print("Example 3: Using Claude (Anthropic)")
    print("=" * 60)
    
    import os
    
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("‚ùå ANTHROPIC_API_KEY not set")
        return
    
    llm_config = LLMConfig(
        provider="anthropic",
        model="claude-3-sonnet-20240229",
        api_key=api_key
    )
    
    doc_config = DocumentationConfig(
        output_dir="docs",
        input_dir="examples",
        language="ru"
    )
    
    try:
        llm = get_llm_from_config(llm_config)
        generator = AdvancedOpenAPIDocGenerator(llm, output_dir=doc_config.output_dir)
        generator.process_directory(doc_config.input_dir)
    except Exception as e:
        print(f"Error: {e}")


def example_english_documentation():
    """–ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ."""
    print("=" * 60)
    print("Example 4: English Documentation")
    print("=" * 60)
    
    llm_config = LLMConfig(
        provider="ollama",
        model="mistral"
    )
    
    try:
        llm = get_llm_from_config(llm_config)
        generator = AdvancedOpenAPIDocGenerator(
            llm, 
            output_dir="docs_en",
            language="en"  # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫
        )
        generator.process_directory("examples")
    except Exception as e:
        print(f"Error: {e}")


def example_specific_files():
    """–ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
    print("=" * 60)
    print("Example 5: Process Specific Files")
    print("=" * 60)
    
    llm_config = LLMConfig(provider="ollama", model="mistral")
    
    try:
        llm = get_llm_from_config(llm_config)
        generator = AdvancedOpenAPIDocGenerator(llm)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–∞–π–ª—ã
        specific_files = [
            "examples/petstore.json",
            "examples/petstore-expanded.json"
        ]
        
        for file in specific_files:
            if Path(file).exists():
                generator.process_openapi_file(file)
            else:
                print(f"File not found: {file}")
    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    """–ó–∞–ø—É—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤."""
    print("\nüöÄ OpenAPI Documentation Generator Examples\n")
    
    # –í—ã–±–∏—Ä–∞–µ–º, –∫–∞–∫–æ–π –ø—Ä–∏–º–µ—Ä –∑–∞–ø—É—Å—Ç–∏—Ç—å
    examples = {
        "1": ("Ollama (Local)", example_with_ollama),
        "2": ("OpenAI GPT", example_with_openai),
        "3": ("Claude (Anthropic)", example_with_anthropic),
        "4": ("English Docs", example_english_documentation),
        "5": ("Specific Files", example_specific_files),
    }
    
    print("Available examples:")
    for key, (name, _) in examples.items():
        print(f"  {key}. {name}")
    
    print("\nUsage:")
    print("  python examples.py <number>")
    print("  Example: python examples.py 1\n")
    
    import sys
    
    if len(sys.argv) > 1:
        choice = sys.argv[1]
        if choice in examples:
            _, func = examples[choice]
            func()
        else:
            print(f"‚ùå Invalid choice: {choice}")
    else:
        print("üí° Running Ollama example by default...")
        example_with_ollama()
